{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vy-ZpJ3jJa-",
        "outputId": "044e31b7-bdb9-4b43-dbc4-6b4e0043fe44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.10/dist-packages (2.90)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyttsx3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eclX3sWTiy6q"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import pyttsx3\n",
        "from scipy.spatial import distance\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from ipywidgets import Image\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWWoh73IjQAu",
        "outputId": "2e00fbf5-b2d5-45dc-98e2-95ef6e93e471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libespeak1 is already the newest version (1.48.15+dfsg-3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Initialize pyttsx3 for audio alerts\n",
        "!apt-get install libespeak1\n",
        "engine = pyttsx3.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cevvwyz4kPfR",
        "outputId": "a621adb8-53af-491a-a92f-b459cdf79ec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-17 16:28:37--  https://drive.google.com/uc?id=1r4FaTkYHbR0qaU2fMJ7XLFakk1SqlxOV\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.139.102, 74.125.139.100, 74.125.139.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.139.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1r4FaTkYHbR0qaU2fMJ7XLFakk1SqlxOV [following]\n",
            "--2024-03-17 16:28:37--  https://drive.usercontent.google.com/download?id=1r4FaTkYHbR0qaU2fMJ7XLFakk1SqlxOV\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.134.132, 2607:f8b0:400c:c00::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.134.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 99693937 (95M) [application/octet-stream]\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  95.08M  72.6MB/s    in 1.3s    \n",
            "\n",
            "2024-03-17 16:28:44 (72.6 MB/s) - ‘shape_predictor_68_face_landmarks.dat’ saved [99693937/99693937]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load face detector and facial landmark predictor\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "!wget -O shape_predictor_68_face_landmarks.dat \"https://drive.google.com/uc?id=1r4FaTkYHbR0qaU2fMJ7XLFakk1SqlxOV\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uLmYeJhRk5wo"
      },
      "outputs": [],
      "source": [
        "dlib_facelandmark = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-Uo_o_aKk_PK"
      },
      "outputs": [],
      "source": [
        "# Function to calculate eye aspect ratio\n",
        "def Detect_Eye(eye):\n",
        "    poi_A = distance.euclidean(eye[1], eye[5])\n",
        "    poi_B = distance.euclidean(eye[2], eye[4])\n",
        "    poi_C = distance.euclidean(eye[0], eye[3])\n",
        "    aspect_ratio_Eye = (poi_A + poi_B) / (2 * poi_C)\n",
        "    return aspect_ratio_Eye\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KuHZU3tJlGlG"
      },
      "outputs": [],
      "source": [
        "# Function to capture photo using JavaScript\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Capture a frame when the \"Capture\" button is clicked.\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    # Get the photo data\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    # Write the photo to the file.\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WFVPpM5slN4A"
      },
      "outputs": [],
      "source": [
        "# Create an Image widget\n",
        "image_widget = Image()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "YG6u94gHlTWo",
        "outputId": "7c056d58-8830-4c6e-e735-7bc5f0874cfa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const capture = document.createElement('button');\n",
              "            capture.textContent = 'Capture';\n",
              "            div.appendChild(capture);\n",
              "\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Resize the output to fit the video element.\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            // Capture a frame when the \"Capture\" button is clicked.\n",
              "            await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALERT : DROWSINESS DETECTED\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const capture = document.createElement('button');\n",
              "            capture.textContent = 'Capture';\n",
              "            div.appendChild(capture);\n",
              "\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Resize the output to fit the video element.\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            // Capture a frame when the \"Capture\" button is clicked.\n",
              "            await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - DROWSINESS NOT DETECTED\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const capture = document.createElement('button');\n",
              "            capture.textContent = 'Capture';\n",
              "            div.appendChild(capture);\n",
              "\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Resize the output to fit the video element.\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            // Capture a frame when the \"Capture\" button is clicked.\n",
              "            await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALERT : DROWSINESS DETECTED\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const capture = document.createElement('button');\n",
              "            capture.textContent = 'Capture';\n",
              "            div.appendChild(capture);\n",
              "\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Resize the output to fit the video element.\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            // Capture a frame when the \"Capture\" button is clicked.\n",
              "            await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Main loop\n",
        "while True:\n",
        "    # Capture photo\n",
        "    take_photo('photo.jpg')\n",
        "\n",
        "    # Read the captured photo\n",
        "    frame = cv2.imread('photo.jpg')\n",
        "\n",
        "    # Convert the frame to grayscale\n",
        "    gray_scale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces in the grayscale frame\n",
        "    faces = face_detector(gray_scale)\n",
        "\n",
        "    for face in faces:\n",
        "        # Get the face landmarks\n",
        "        face_landmarks = dlib_facelandmark(gray_scale, face)\n",
        "        leftEye = []\n",
        "        rightEye = []\n",
        "\n",
        "        # Extract left and right eye coordinates\n",
        "        for n in range(42, 48):\n",
        "            x = face_landmarks.part(n).x\n",
        "            y = face_landmarks.part(n).y\n",
        "            rightEye.append((x, y))\n",
        "            next_point = n+1\n",
        "            if n == 47:\n",
        "                next_point = 42\n",
        "            x2 = face_landmarks.part(next_point).x\n",
        "            y2 = face_landmarks.part(next_point).y\n",
        "            cv2.line(frame, (x, y), (x2, y2), (0, 255, 0), 1)\n",
        "\n",
        "        for n in range(36, 42):\n",
        "            x = face_landmarks.part(n).x\n",
        "            y = face_landmarks.part(n).y\n",
        "            leftEye.append((x, y))\n",
        "            next_point = n+1\n",
        "            if n == 41:\n",
        "                next_point = 36\n",
        "            x2 = face_landmarks.part(next_point).x\n",
        "            y2 = face_landmarks.part(next_point).y\n",
        "            cv2.line(frame, (x, y), (x2, y2), (255, 255, 0), 1)\n",
        "\n",
        "        # Calculate the aspect ratio for left and right eye\n",
        "        right_Eye = Detect_Eye(rightEye)\n",
        "        left_Eye = Detect_Eye(leftEye)\n",
        "        Eye_Rat = (left_Eye+right_Eye)/2\n",
        "\n",
        "        # This value of 0.25 (you can even change it)\n",
        "        # will decide whether the person's eyes are close or not\n",
        "        if Eye_Rat < 0.25:\n",
        "            print(\"ALERT : DROWSINESS DETECTED\")\n",
        "            engine.say(\"Eyes are closed\")\n",
        "            engine.runAndWait()\n",
        "        else:\n",
        "            print(\"0 - DROWSINESS NOT DETECTED\")\n",
        "\n",
        "# Release the camera and close all OpenCV windows\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JShvOieXoczX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}